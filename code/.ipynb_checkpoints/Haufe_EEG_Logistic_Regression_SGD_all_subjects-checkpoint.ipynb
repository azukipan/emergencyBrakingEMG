{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code produces an EEG dataset according to the methodology described by Haufe et al. in \"EEG potentials predict upcoming emergency brakings during simulated driving.\" dx.doi.org/10.1088/1741-2560/8/5/056001. Instead of the original modeling approach, we train and test our own model here for all test subjects from the Haufe et al. study. \n",
    "\n",
    "The original EEG data are part of a dataset from Haufe et al. called \"Emergency braking during simulated driving.\" The dataset is available at http://bnci-horizon-2020.eu/database/data-sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll iterate through all the test subject data files to create our train and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import spectrogram\n",
    "from statistics import mean\n",
    "\n",
    "#Create training data from braking event EEG via these steps:\n",
    "#Get segments of braking event EEG.\n",
    "#Covert to PSD.\n",
    "#Store PSD components of each segment in variable for training.\n",
    "def createDatasetFromEEGEvents(timestamps, data, samplingRate, numberOfPSDComponents = 4):\n",
    "    dt = 1/samplingRate #Time increment in seconds\n",
    "    \n",
    "    dt1_index = 0\n",
    "    dt2_index = int(100/1000/dt) #Covert timestamps to seconds and divde by time increment to get index of datapoint at 100 ms.\n",
    "    baselineCorrection_eeg = mean(data[dt1_index:dt2_index+1])\n",
    "    \n",
    "    #Define variables to split data in first 1/2 for training and second 1/2 for validation\n",
    "    brakingEvent_eeg_PSD_train = []\n",
    "    brakingEvent_eeg_PSD_val = []\n",
    "\n",
    "    dt = 1/samplingRate #Time increment in seconds\n",
    "\n",
    "    for time in timestamps: #Iterate through event timestamps in milliseconds\n",
    "        #index = int(time/1000/dt) #Covert timestamps to seconds and divde by time increment to get index of datapoint\n",
    "        dt1_index = int((time-300)/1000/dt) #Index of datapoint 300 ms before event datapoint.\n",
    "        dt2_index = int((time+1200)/1000/dt) #Index of datapoint 1200 ms after event datapoint.\n",
    "\n",
    "        brakingEvent_eeg = data[dt1_index:dt2_index+1]-baselineCorrection_eeg\n",
    "        #Normalize signal data WRT to max and find generate power spectral density \n",
    "        freq_data, time_data, pwr_spectral_density_data = spectrogram(\n",
    "                                                            np.array([brakingEvent_eeg]),#/max(brakingEvent_eeg)]), \n",
    "                                                            samplingRate\n",
    "                                                            )\n",
    "        if time < len(data)*1000*dt/2:\n",
    "            brakingEvent_eeg_PSD_train.append(np.sort(np.sum(pwr_spectral_density_data[0],1))[-numberOfPSDComponents:None].tolist())\n",
    "            continue\n",
    "        brakingEvent_eeg_PSD_val.append(np.sort(np.sum(pwr_spectral_density_data[0],1))[-numberOfPSDComponents:None].tolist())\n",
    "        \n",
    "    return brakingEvent_eeg_PSD_train, brakingEvent_eeg_PSD_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create baseline training EEG data containing no braking event EEG via these steps:\n",
    "#Get 100 ms EEG segment at beginning of data to use for baseline correction.\n",
    "#Get segments of EEG without braking events and subract 100 ms EEG segment.\n",
    "#Covert to PSD.\n",
    "#Store PSD components of each segment in variable for training.\n",
    "\n",
    "def createDatasetFromEEGWithoutEvents(timestamps, data, samplingRate, numberOfPSDComponents=4):\n",
    "    dt = 1/samplingRate #Time increment in seconds\n",
    "    \n",
    "    dt1_index = 0\n",
    "    dt2_index = int(100/1000/dt) #Covert timestamps to seconds and divde by time increment to get index of datapoint at 100 ms.\n",
    "    baselineCorrection_eeg = mean(data[dt1_index:dt2_index+1])\n",
    "\n",
    "    noEvent_eeg_PSD_train = []\n",
    "    noEvent_eeg_PSD_val = []\n",
    "\n",
    "    for i in range(0, len(timestamps)): #Iterate through all event timestamps in milliseconds\n",
    "        if timestamps[i][0] < 4500: #Skip iteration if there is not enough time to get an EEG segment between time of first datapoint and time of first event. \n",
    "            continue\n",
    "\n",
    "        if i > 0:\n",
    "            if timestamps[i][0]-timestamps[i-1][0] < 7500: #Skip iteration if there is not enough time to get EEG segment between current and previous timestamps.\n",
    "                continue\n",
    "\n",
    "        numberOfSegments = int((timestamps[i][0]-timestamps[i-1][0]-6000)/2000) #Calculate how many user-specified EEG segments can fit between two events.\n",
    "        \n",
    "        for segmentNum in range(0, numberOfSegments):\n",
    "            #Add 500 ms between each EEG segment, except for segment closest in time to event\n",
    "            dt1_index = int((timestamps[i][0]-5000-(2000*segmentNum)-500)/1000/dt) #500 represents 500 ms offset between each EEG segment.\n",
    "            dt2_index = int((timestamps[i][0]-3000-(2000*segmentNum))/1000/dt)\n",
    "            \n",
    "            noEvent_eeg = data[dt1_index:dt2_index+1]-baselineCorrection_eeg #Get EEG segment immediately prior to current event.\n",
    "           \n",
    "            #Normalize signal data WRT to max and find generate power spectral density \n",
    "            freq_data, time_data, pwr_spectral_density_data = spectrogram( \n",
    "                                                                np.array([noEvent_eeg]),#/max(noEvent_eeg)]), \n",
    "                                                                samplingRate\n",
    "                                                                )\n",
    "            \n",
    "            if timestamps[i][0] < len(data)*1000*dt/2: #Check if timestamp is less half than total time of EEG data.\n",
    "                noEvent_eeg_PSD_train.append(np.sort(np.sum(pwr_spectral_density_data[0],1))[-numberOfPSDComponents:None].tolist())\n",
    "                continue\n",
    "            noEvent_eeg_PSD_val.append(np.sort(np.sum(pwr_spectral_density_data[0],1))[-numberOfPSDComponents:None].tolist())\n",
    "           \n",
    "        if i == len(timestamps): #If iteration reaches last event timestamp, set indices to get any possible EEG segment beyond timestamp.\n",
    "            numberOfSegments = int((len(data)*1000*dt/2-timestamps[i][0])/2000) #Calculate how many user-specified EEG segments can fit between two events.\n",
    "\n",
    "            for segmentNum in range(0, numberOfSegments):\n",
    "                #Add 500 ms between each EEG segment, except for segment closest in time to event\n",
    "                dt1_index = int((timestamps[i][0]+3000+(2000*segmentNum))/1000/dt)\n",
    "                dt2_index = int((timestamps[i][0]+5000+(2000*segmentNum)-500)/1000/dt) #500 represents 500 ms offset between each EEG segment.\n",
    "\n",
    "                noEvent_eeg = data[dt1_index:dt2_index+1]  #Get EEG segment \n",
    "                #Normalize signal data WRT to max and find generate power spectral density \n",
    "                freq_data, time_data, pwr_spectral_density_data = spectrogram( \n",
    "                                                                    np.array([noEvent_eeg]),#/max(noEvent_eeg)]), \n",
    "                                                                    samplingRate\n",
    "                                                                    )\n",
    "                if timestamps[i][0] < len(data)*1000*dt/2:\n",
    "                    noEvent_eeg_PSD_train.append(np.sort(np.sum(pwr_spectral_density_data[0],1))[-numberOfPSDComponents:None].tolist())\n",
    "                    continue\n",
    "                noEvent_eeg_PSD_val.append(np.sort(np.sum(pwr_spectral_density_data[0],1))[-numberOfPSDComponents:None].tolist())\n",
    "        \n",
    "    return noEvent_eeg_PSD_train, noEvent_eeg_PSD_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create datasets, train model, and evaluate trained model.\n",
    "\n",
    "def createDatasets(brakingEvent_eeg_PSD_train, noEvent_eeg_PSD_train, brakingEvent_eeg_PSD_val, noEvent_eeg_PSD_val):\n",
    "    #Label = 0 indicates no event; label = 1 indicates EEG braking event\n",
    "    trainData = np.concatenate((brakingEvent_eeg_PSD_train, noEvent_eeg_PSD_train))\n",
    "    trainLabels_event = np.ones(len(brakingEvent_eeg_PSD_train),dtype=int) \n",
    "    trainLabels_noEvent = np.zeros(len(noEvent_eeg_PSD_train),dtype=int) \n",
    "    trainLabels = np.concatenate((trainLabels_event, trainLabels_noEvent))\n",
    "\n",
    "    valData = np.concatenate((brakingEvent_eeg_PSD_val, noEvent_eeg_PSD_val))\n",
    "    valLabels_event = np.ones(len(brakingEvent_eeg_PSD_val),dtype=int) \n",
    "    valLabels_noEvent = np.zeros(len(noEvent_eeg_PSD_val),dtype=int) \n",
    "    valLabels = np.concatenate((valLabels_event, valLabels_noEvent))\n",
    "    \n",
    "    return trainData, trainLabels, valData, valLabels\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def trainModel(trainData, trainLabels):\n",
    "    \n",
    "    model = make_pipeline(StandardScaler(), SGDClassifier(loss = 'log'))\n",
    "    model.fit(np.array(trainData), trainLabels)\n",
    "    \n",
    "    return model\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def evaluateModel(model, valData, valLabels):\n",
    "    #Validate model\n",
    "    #eventPredictions = model.predict(valData).tolist()\n",
    "    #Accuracy as percent of correct predictions out of total predictions.\n",
    "    #accuracy = abs(sum(eventPredictions-valLabels))/len(eventPredictions)\n",
    "    \n",
    "    #Area under the curve score\n",
    "    #AUCaccuracy = roc_auc_score(valLabels, model.predict_proba(np.array(valData))[:, 1])\n",
    "    AUCaccuracy = roc_auc_score(valLabels, model.predict_proba(np.array(valData))[:, 1])\n",
    "    \n",
    "    return AUCaccuracy #,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test subject data: 100%|████████████████████████████████████████████████████| 18/18 [02:21<00:00,  7.88s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Find all paths for the test subject data.\n",
    "testSubjectDataFilePaths =  glob('../../EEG_Dataset_Haufe/*.mat')\n",
    "\n",
    "allTestSubjectAUCs = []\n",
    "\n",
    "numberOfPSDComponents = 129 #Maximum number of components for samplingRate = 200 hz.\n",
    "\n",
    "channelsOfInterest = ['POz'] #<-- 96.7%, 126 components\n",
    "#['P9'] #<-- 96.3% accuracy, 126 components\n",
    "#['P10'] #<-- 96.5% accuracy, 126 components\n",
    "#['FCz'] #<-- 96.1% accuracy, 126 components\n",
    "#['POz','FCz'] #<-- 96.3%, 126 components\n",
    "#['CPz'] #<-- 96.8%, 126 components\n",
    "#['CPz', 'POz'] #<-- 96.8%, 126 components\n",
    "#['P9', 'P10', 'CPz', 'FCz'] #<-- 95.6%, 126 components\n",
    "#['all channels'] #<-- 94.8%; 126, components\n",
    "\n",
    "pbar1 = tqdm(testSubjectDataFilePaths)\n",
    "pbar1.set_description('Processing test subject data')\n",
    "for path in pbar1:\n",
    "    f = h5py.File(path,'r')\n",
    "    '''\n",
    "    Read, sort and assign experimental to variables for: \n",
    "    signal channel names: cnt.clab\n",
    "    sampling frequency: cnt.fs\n",
    "    time-series data: cnt.x\n",
    "    '''\n",
    "    cnt = f.get('cnt')\n",
    "    cnt.clab = np.array(cnt['clab'])\n",
    "    cnt.fs = np.array(cnt['fs'])\n",
    "    cnt.x = np.array(cnt['x']) \n",
    "\n",
    "    samplingRate = cnt.fs[0][0] #Down-/upsample rate for all data = 200Hz.\n",
    "    \n",
    "    #Read data for events corresponding to experimental data.\n",
    "    mrk = f.get('mrk')\n",
    "    mrk.classNames = mrk['className']\n",
    "    mrk.time = mrk['time']\n",
    "    mrk.y = mrk['y']\n",
    "    mrk.events = mrk['event']\n",
    "    \n",
    "    #Find all car braking events (brake lights of lead vehicle turn on) and store corresponding timestamps.\n",
    "    carBrakeTime = []\n",
    "    for i in range(0, len(mrk.y)):\n",
    "        if mrk.y[i][1] == 1: #Check if car is braking, i.e. y[i] = 1\n",
    "            carBrakeTime.append(mrk.time[i][0]) #Store timestamp \n",
    "            \n",
    "    #Create train and validation datasets\n",
    "    brakingEvent_eeg_PSD_train = []\n",
    "    brakingEvent_eeg_PSD_val = []\n",
    "\n",
    "    noEvent_eeg_PSD_train = []\n",
    "    noEvent_eeg_PSD_val = []\n",
    "\n",
    "    #Iterate through all EEG channels.\n",
    "    #pbar2 = tqdm(range(0, 61))\n",
    "    #pbar2.set_description('Iterating through EEG channels')\n",
    "    #for channelNum in pbar2:\n",
    "    for channelNum in range(0, 61):\n",
    "        \n",
    "        if channelsOfInterest != ['all channels']:\n",
    "            ref = cnt.clab[channelNum][0]\n",
    "            channelName = bytes(np.array(cnt[ref]).ravel().tolist()).decode('UTF-8')\n",
    "\n",
    "            if channelName not in channelsOfInterest:\n",
    "                continue\n",
    "        \n",
    "        data = cnt.x[channelNum]\n",
    "        event_eeg_PSD_train, event_eeg_PSD_val = createDatasetFromEEGEvents(carBrakeTime, \n",
    "                                                                            data, \n",
    "                                                                            samplingRate, \n",
    "                                                                            numberOfPSDComponents)\n",
    "        _noEvent_eeg_PSD_train, _noEvent_eeg_PSD_val = createDatasetFromEEGWithoutEvents(mrk.time, \n",
    "                                                                                         data, \n",
    "                                                                                         samplingRate, \n",
    "                                                                                         numberOfPSDComponents)\n",
    "        \n",
    "        for array in event_eeg_PSD_train: brakingEvent_eeg_PSD_train.append(array)\n",
    "        for array in event_eeg_PSD_val: brakingEvent_eeg_PSD_val.append(array)\n",
    "        for array in _noEvent_eeg_PSD_train: noEvent_eeg_PSD_train.append(array)\n",
    "        for array in _noEvent_eeg_PSD_val: noEvent_eeg_PSD_val.append(array)\n",
    "        \n",
    "    trainData, trainLabels, valData, valLabels = createDatasets(brakingEvent_eeg_PSD_train,\n",
    "                                                                noEvent_eeg_PSD_train,\n",
    "                                                                brakingEvent_eeg_PSD_val,\n",
    "                                                                noEvent_eeg_PSD_val)\n",
    "    trainedModel = trainModel(trainData, trainLabels)\n",
    "    AUCaccuracy = evaluateModel(trainedModel, valData, valLabels)\n",
    "    allTestSubjectAUCs.append(AUCaccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM model AUC accuracy:  0.967\n"
     ]
    }
   ],
   "source": [
    "grandAverageAUC = mean(allTestSubjectAUCs)\n",
    "print(\"SVM model AUC accuracy: \", round(grandAverageAUC,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
